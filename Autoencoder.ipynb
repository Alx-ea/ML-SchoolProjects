{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlYaZ3aODO4I",
        "outputId": "ead81382-0f15-489f-bf6f-cee580ed78d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "6/6 [==============================] - 1s 41ms/step - loss: 0.7070 - val_loss: 0.7020\n",
            "Epoch 2/50\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6995 - val_loss: 0.6948\n",
            "Epoch 3/50\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6922 - val_loss: 0.6875\n",
            "Epoch 4/50\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6848 - val_loss: 0.6801\n",
            "Epoch 5/50\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6772 - val_loss: 0.6724\n",
            "Epoch 6/50\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6693 - val_loss: 0.6644\n",
            "Epoch 7/50\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.6609 - val_loss: 0.6559\n",
            "Epoch 8/50\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6521 - val_loss: 0.6469\n",
            "Epoch 9/50\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6429 - val_loss: 0.6374\n",
            "Epoch 10/50\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.6331 - val_loss: 0.6274\n",
            "Epoch 11/50\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.6229 - val_loss: 0.6170\n",
            "Epoch 12/50\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.6122 - val_loss: 0.6061\n",
            "Epoch 13/50\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.6011 - val_loss: 0.5947\n",
            "Epoch 14/50\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.5895 - val_loss: 0.5828\n",
            "Epoch 15/50\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.5774 - val_loss: 0.5705\n",
            "Epoch 16/50\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.5648 - val_loss: 0.5578\n",
            "Epoch 17/50\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.5520 - val_loss: 0.5452\n",
            "Epoch 18/50\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.5394 - val_loss: 0.5330\n",
            "Epoch 19/50\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.5274 - val_loss: 0.5214\n",
            "Epoch 20/50\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.5160 - val_loss: 0.5106\n",
            "Epoch 21/50\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.5054 - val_loss: 0.5006\n",
            "Epoch 22/50\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4957 - val_loss: 0.4916\n",
            "Epoch 23/50\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.4870 - val_loss: 0.4834\n",
            "Epoch 24/50\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.4792 - val_loss: 0.4762\n",
            "Epoch 25/50\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.4722 - val_loss: 0.4699\n",
            "Epoch 26/50\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4661 - val_loss: 0.4643\n",
            "Epoch 27/50\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.4607 - val_loss: 0.4594\n",
            "Epoch 28/50\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.4560 - val_loss: 0.4550\n",
            "Epoch 29/50\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.4519 - val_loss: 0.4512\n",
            "Epoch 30/50\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.4482 - val_loss: 0.4479\n",
            "Epoch 31/50\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.4449 - val_loss: 0.4449\n",
            "Epoch 32/50\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.4420 - val_loss: 0.4422\n",
            "Epoch 33/50\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.4394 - val_loss: 0.4398\n",
            "Epoch 34/50\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.4370 - val_loss: 0.4376\n",
            "Epoch 35/50\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.4349 - val_loss: 0.4356\n",
            "Epoch 36/50\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.4330 - val_loss: 0.4338\n",
            "Epoch 37/50\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.4312 - val_loss: 0.4321\n",
            "Epoch 38/50\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.4295 - val_loss: 0.4306\n",
            "Epoch 39/50\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.4280 - val_loss: 0.4292\n",
            "Epoch 40/50\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.4266 - val_loss: 0.4279\n",
            "Epoch 41/50\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4253 - val_loss: 0.4266\n",
            "Epoch 42/50\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4240 - val_loss: 0.4255\n",
            "Epoch 43/50\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4228 - val_loss: 0.4244\n",
            "Epoch 44/50\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4217 - val_loss: 0.4234\n",
            "Epoch 45/50\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4206 - val_loss: 0.4224\n",
            "Epoch 46/50\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4196 - val_loss: 0.4214\n",
            "Epoch 47/50\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4186 - val_loss: 0.4205\n",
            "Epoch 48/50\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4177 - val_loss: 0.4196\n",
            "Epoch 49/50\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.4167 - val_loss: 0.4188\n",
            "Epoch 50/50\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4158 - val_loss: 0.4180\n",
            "12/12 [==============================] - 0s 2ms/step\n",
            "Encoded features of the first few test samples:\n",
            "[[4.7653446 4.217446  2.167966  4.6692967]]\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the digits dataset\n",
        "digits = load_digits()\n",
        "X = digits.data\n",
        "y = digits.target\n",
        "\n",
        "# Normalizing the data\n",
        "X = X / 16.0\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Size of encoded representations\n",
        "encoding_dim = 4  # for example, 4 floats -> compression of factor 64/4 = 16\n",
        "\n",
        "# Input placeholder\n",
        "input_img = Input(shape=(64,))\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "decoded = Dense(64, activation='sigmoid')(encoded)\n",
        "\n",
        "# This model maps an input to its reconstruction\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# This model maps an input to its encoded representation\n",
        "encoder = Model(input_img, encoded)\n",
        "\n",
        "# Compile the autoencoder\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the autoencoder\n",
        "autoencoder.fit(X_train, X_train, epochs=50, batch_size=256, shuffle=True, validation_data=(X_test, X_test))\n",
        "\n",
        "# Encode some digits from the test set\n",
        "encoded_imgs = encoder.predict(X_test)\n",
        "\n",
        "# Printing the desired features from latent space\n",
        "print(\"Encoded features of the first few test samples:\")\n",
        "print(encoded_imgs[:1])\n"
      ]
    }
  ]
}